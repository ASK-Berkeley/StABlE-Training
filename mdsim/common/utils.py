import ast
import collections
import copy
import glob
import importlib
import itertools
import json
import logging
import os
import re
import sys
import gc
import time
from bisect import bisect
from functools import wraps
from itertools import product
from scipy.stats import maxwell
from nequip.utils import atomic_write
from nequip.data import AtomicData, AtomicDataDict
from torch_geometric.data import Data
from pathlib import Path
import numpy as np
import torch
import yaml
from ase import Atoms
from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas
from matplotlib.figure import Figure
from mdsim.datasets.lmdb_dataset import data_list_collater
from torch_geometric.utils import remove_self_loops
from torch_scatter import segment_coo, segment_csr
from torch_cluster import radius_graph as pyg_radius_graph


HARTREE_TO_KCAL_MOL = 627.509
EV_TO_KCAL_MOL = 23.06052

OFFSET_LIST = [
    [-1, -1, -1],
    [-1, -1, 0],
    [-1, -1, 1],
    [-1, 0, -1],
    [-1, 0, 0],
    [-1, 0, 1],
    [-1, 1, -1],
    [-1, 1, 0],
    [-1, 1, 1],
    [0, -1, -1],
    [0, -1, 0],
    [0, -1, 1],
    [0, 0, -1],
    [0, 0, 0],
    [0, 0, 1],
    [0, 1, -1],
    [0, 1, 0],
    [0, 1, 1],
    [1, -1, -1],
    [1, -1, 0],
    [1, -1, 1],
    [1, 0, -1],
    [1, 0, 0],
    [1, 0, 1],
    [1, 1, -1],
    [1, 1, 0],
    [1, 1, 1],
]

"""
These function were written for StABlE Training. 
"""


def extract_cycle_epoch(s):
    # Regular expression to match the pattern
    pattern = r"post_cycle(\d+)(?:_epoch(\d+))?"

    # Search for matches
    match = re.search(pattern, s)

    if match:
        cycle = match.group(1)
        epoch = match.group(2) if match.group(2) else None
        return cycle, epoch
    else:
        return None, None


def cleanup_atoms_batch(atoms_batch):
    for key in ["cell_offsets", "edge_cell_shift", "edge_index", "neighbors", "ptr"]:
        if key in atoms_batch:
            del atoms_batch[key]
    return atoms_batch


# Procedure to initialize velocities with Maxwell Boltzmann Distribution
def initialize_velocities(n_particle, masses, temp, n_replicas):

    masses = masses.cpu().numpy()
    vel_dist = maxwell()
    momenta = masses * vel_dist.rvs(size=(n_replicas, n_particle, 3))
    # shift so that initial momentum is zero
    momenta -= np.mean(momenta, axis=-2, keepdims=True)

    # scale velocities to match desired temperature
    ke = (momenta**2 / (2 * masses)).sum(axis=(1, 2), keepdims=True)
    targeEkin = 0.5 * (3.0 * n_particle) * temp
    correction_factor = np.sqrt(targeEkin / ke)
    momenta *= correction_factor
    velocities = momenta / masses
    return torch.Tensor(velocities)


# inverse cdf for power law with exponent 'power' and min value y_min
def powerlaw_inv_cdf(y, power, y_min):
    return y_min * ((1 - y) ** (1 / (1 - power)))


def dump_params_to_yml(params, filepath):
    with open(os.path.join(filepath, "stable_training_config.yml"), "w") as f:
        yaml.dump(params, f)


def print_active_torch_tensors():
    count = 0
    for obj in gc.get_objects():
        try:
            if torch.is_tensor(obj) or (
                hasattr(obj, "data") and torch.is_tensor(obj.data)
            ):
                # print(type(obj), obj.size())
                count += 1
                del obj
        except:
            pass
    print(f"{count} tensors in memory")


"""Gradient utils"""


def compare_gradients(grad1, grad2):
    """Compute cosine similarity and ratio between two sets of gradient updates for a given model"""
    assert len(grad1) == len(grad2)
    grads1_flattened = torch.cat([grad.flatten() for grad in grad1])
    grads2_flattened = torch.cat([grad.flatten() for grad in grad2])
    cosine_similarity = torch.nn.functional.cosine_similarity(
        grads1_flattened, grads2_flattened, dim=0
    )
    ratio = (grads1_flattened / (grads2_flattened + 1e-8)).abs().median()
    return cosine_similarity, ratio


def process_gradient(params, grads, device):
    return [
        g.detach() if g is not None else torch.zeros_like(param).to(device)
        for g, param in zip(grads, params)
    ]


def convert_atomic_numbers_to_types(atomic_numbers):
    unique_atomic_numbers = torch.unique(atomic_numbers)
    atomic_number_to_type = {
        num.item(): idx for idx, num in enumerate(unique_atomic_numbers)
    }

    atomic_types = torch.tensor(
        [atomic_number_to_type[num.item()] for num in atomic_numbers]
    )
    return atomic_types


def get_atomic_types(atom_dict):
    # assumes that all samples in batch are from the same molecule and thus the atomic types are all identical

    nums = torch.tensor(sorted(torch.unique(atom_dict["atomic_numbers"][0]))).unsqueeze(
        -1
    )
    atomic_types = torch.zeros_like(atom_dict["atomic_numbers"][0])
    for i in range(atomic_types.shape[0]):
        atomic_types[i] = torch.where(nums == atom_dict["atomic_numbers"][0, i])[0]

    return (
        atomic_types.unsqueeze(0)
        .repeat(atom_dict["atomic_numbers"].shape[0], 1, 1)
        .to(torch.int64)
    )


def atoms_to_batch(atoms, device):
    # convert list of atoms to a torch.geometric.data.Batch object
    data = []
    for atom in atoms:
        atomic_numbers = torch.Tensor(atom.get_atomic_numbers())
        positions = torch.Tensor(atom.get_positions())
        cell = torch.Tensor(np.array(atom.get_cell())).view(1, 3, 3)
        natoms = positions.shape[0]

        data.append(
            Data(
                cell=cell,
                pos=positions,
                atomic_numbers=atomic_numbers,
                natoms=natoms,
            )
        )

    return data_list_collater(data, otf_graph=True).to(device)


def data_to_atoms(data):
    numbers = data.atomic_numbers
    positions = data.pos
    cell = data.cell.squeeze()
    atoms = Atoms(
        numbers=numbers,
        positions=positions.cpu().detach().numpy(),
        cell=cell.cpu().detach().numpy(),
        pbc=[True, True, True],
    )
    return atoms


def dictdata_to_atoms(data):
    # Now operates on batches
    batch_size = data["atomic_numbers"].shape[0]

    atoms_objects = []
    for i in range(batch_size):
        atoms = Atoms(
            numbers=data["atomic_numbers"][i].squeeze().cpu(),
            positions=data["pos"][i].cpu(),
            cell=data["cell"][i].cpu(),
            pbc=[True, True, True],
        )
        atoms_objects.append(atoms)
    return atoms_objects


def batch_to_atoms(batch):
    n_systems = batch.natoms.shape[0]
    natoms = batch.natoms.tolist()
    numbers = torch.split(batch.atomic_numbers, natoms)
    forces = torch.split(batch.force, natoms)
    positions = torch.split(batch.pos, natoms)
    # tags = torch.split(batch.tags, natoms)
    cells = batch.cell
    if batch.y is not None:
        energies = batch.y.tolist()
    else:
        energies = [None] * n_systems

    atoms_objects = []
    for idx in range(n_systems):
        atoms = Atoms(
            numbers=numbers[idx].tolist(),
            positions=positions[idx].cpu().detach().numpy(),
            cell=cells[idx].cpu().detach().numpy(),
            pbc=[True, True, True],
        )
        calc = sp(
            atoms=atoms,
            energy=energies[idx],
            forces=forces[idx].cpu().detach().numpy(),
        )
        atoms.set_calculator(calc)
        atoms_objects.append(atoms)

    return atoms_objects


def compute_bond_lengths(atoms, bonds=None, r_max=5):

    data = AtomicData.from_ase(atoms, r_max)
    data = AtomicData.to_AtomicDataDict(data)

    if bonds is None:
        bonds = torch.unique(data["edge_index"], dim=1)

    pos = torch.tensor(atoms.get_positions())
    bond_lens = distance_pbc(
        pos[bonds[0]], pos[bonds[1]], torch.FloatTensor([30.0, 30.0, 30.0])
    )

    return bond_lens, bonds


def distance_pbc(x0, x1, lattices):
    delta = torch.abs(x0 - x1)
    lattices = lattices.view(-1, 1, 3)
    delta = torch.where(delta > 0.5 * lattices, delta - lattices, delta)
    return torch.sqrt((delta**2).sum(dim=-1))


def atoms_to_state_dict(atoms, r_max):
    data = AtomicData.from_ase(atoms=atoms, r_max=r_max)
    for k in AtomicDataDict.ALL_ENERGY_KEYS:
        if k in data:
            del data[k]
    data = AtomicData.to_AtomicDataDict(data)
    return data


"""
Everything below this point was taken from https://github.com/kyonofx/MDsim/blob/main/mdsim/common/utils.py
"""


def save_checkpoint(state, checkpoint_dir="", checkpoint_file="checkpoint.pt"):
    filename = os.path.join(checkpoint_dir, checkpoint_file)
    torch.save(state, filename)


class Complete(object):
    def __call__(self, data):
        device = data.edge_index.device

        row = torch.arange(data.num_nodes, dtype=torch.long, device=device)
        col = torch.arange(data.num_nodes, dtype=torch.long, device=device)

        row = row.view(-1, 1).repeat(1, data.num_nodes).view(-1)
        col = col.repeat(data.num_nodes)
        edge_index = torch.stack([row, col], dim=0)

        edge_attr = None
        if data.edge_attr is not None:
            idx = data.edge_index[0] * data.num_nodes + data.edge_index[1]
            size = list(data.edge_attr.size())
            size[0] = data.num_nodes * data.num_nodes
            edge_attr = data.edge_attr.new_zeros(size)
            edge_attr[idx] = data.edge_attr

        edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)
        data.edge_attr = edge_attr
        data.edge_index = edge_index

        return data


def warmup_lr_lambda(current_step, optim_config):
    """Returns a learning rate multiplier.
    Till `warmup_steps`, learning rate linearly increases to `initial_lr`,
    and then gets multiplied by `lr_gamma` every time a milestone is crossed.
    """

    # keep this block for older configs that have warmup_epochs instead of warmup_steps
    # and lr_milestones are defined in epochs
    if (
        any(x < 100 for x in optim_config["lr_milestones"])
        or "warmup_epochs" in optim_config
    ):
        raise Exception(
            "ConfigError: please define lr_milestones in steps not epochs and define warmup_steps instead of warmup_epochs"
        )

    if current_step <= optim_config["warmup_steps"]:
        alpha = current_step / float(optim_config["warmup_steps"])
        return optim_config["warmup_factor"] * (1.0 - alpha) + alpha
    else:
        idx = bisect(optim_config["lr_milestones"], current_step)
        return pow(optim_config["lr_gamma"], idx)


def print_cuda_usage():
    print("Memory Allocated:", torch.cuda.memory_allocated() / (1024 * 1024))
    print(
        "Max Memory Allocated:",
        torch.cuda.max_memory_allocated() / (1024 * 1024),
    )
    print("Memory Cached:", torch.cuda.memory_cached() / (1024 * 1024))
    print("Max Memory Cached:", torch.cuda.max_memory_cached() / (1024 * 1024))


def conditional_grad(dec):
    "Decorator to enable/disable grad depending on whether force/energy predictions are being made"

    # Adapted from https://stackoverflow.com/questions/60907323/accessing-class-property-as-decorator-argument
    def decorator(func):
        @wraps(func)
        def cls_method(self, *args, **kwargs):
            f = func
            if self.regress_forces and not getattr(self, "direct_forces", 0):
                f = dec(func)
            return f(self, *args, **kwargs)

        return cls_method

    return decorator


def plot_histogram(data, xlabel="", ylabel="", title=""):
    assert isinstance(data, list)

    # Preset
    fig = Figure(figsize=(5, 4), dpi=150)
    canvas = FigureCanvas(fig)
    ax = fig.gca()

    # Plot
    ax.hist(data, bins=20, rwidth=0.9, zorder=3)

    # Axes
    ax.grid(color="0.95", zorder=0)
    ax.set_xlabel(xlabel)
    ax.set_ylabel(ylabel)
    ax.set_title(title)
    fig.tight_layout(pad=2)

    # Return numpy array
    canvas.draw()
    image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
    image_from_plot = image_from_plot.reshape(
        fig.canvas.get_width_height()[::-1] + (3,)
    )

    return image_from_plot


# Override the collation method in `pytorch_geometric.data.InMemoryDataset`
def collate(data_list):
    keys = data_list[0].keys
    data = data_list[0].__class__()

    for key in keys:
        data[key] = []
    slices = {key: [0] for key in keys}

    for item, key in product(data_list, keys):
        data[key].append(item[key])
        if torch.is_tensor(item[key]):
            s = slices[key][-1] + item[key].size(item.__cat_dim__(key, item[key]))
        elif isinstance(item[key], int) or isinstance(item[key], float):
            s = slices[key][-1] + 1
        else:
            raise ValueError("Unsupported attribute type")
        slices[key].append(s)

    if hasattr(data_list[0], "__num_nodes__"):
        data.__num_nodes__ = []
        for item in data_list:
            data.__num_nodes__.append(item.num_nodes)

    for key in keys:
        if torch.is_tensor(data_list[0][key]):
            data[key] = torch.cat(
                data[key], dim=data.__cat_dim__(key, data_list[0][key])
            )
        else:
            data[key] = torch.tensor(data[key])
        slices[key] = torch.tensor(slices[key], dtype=torch.long)

    return data, slices


# Copied from https://github.com/facebookresearch/mmf/blob/master/mmf/utils/env.py#L89.
def setup_imports():
    from mdsim.common.registry import registry

    # First, check if imports are already setup
    has_already_setup = registry.get("imports_setup", no_warning=True)
    if has_already_setup:
        return
    # Automatically load all of the modules, so that
    # they register with registry
    root_folder = registry.get("mdsim_root", no_warning=True)

    if root_folder is None:
        root_folder = os.path.dirname(os.path.abspath(__file__))
        root_folder = os.path.join(root_folder, "..")

    trainer_folder = os.path.join(root_folder, "trainers")
    trainer_pattern = os.path.join(trainer_folder, "**", "*.py")
    datasets_folder = os.path.join(root_folder, "datasets")
    datasets_pattern = os.path.join(datasets_folder, "*.py")
    model_folder = os.path.join(root_folder, "models")
    model_pattern = os.path.join(model_folder, "*.py")
    task_folder = os.path.join(root_folder, "tasks")
    task_pattern = os.path.join(task_folder, "*.py")

    importlib.import_module("mdsim.common.logger")

    files = (
        glob.glob(datasets_pattern, recursive=True)
        + glob.glob(model_pattern, recursive=True)
        + glob.glob(trainer_pattern, recursive=True)
        + glob.glob(task_pattern, recursive=True)
    )

    for f in files:
        for key in ["/trainers", "/datasets", "/models", "/tasks"]:
            if f.find(key) != -1:
                splits = f.split(os.sep)
                file_name = splits[-1]
                module_name = file_name[: file_name.find(".py")]
                importlib.import_module("mdsim.%s.%s" % (key[1:], module_name))

    experimental_folder = os.path.join(root_folder, "../experimental/")
    if os.path.exists(experimental_folder):
        experimental_files = glob.glob(
            experimental_folder + "**/*py",
            recursive=True,
        )
        # Ignore certain directories within experimental
        ignore_file = os.path.join(experimental_folder, ".ignore")
        if os.path.exists(ignore_file):
            ignored = []
            with open(ignore_file) as f:
                for line in f.read().splitlines():
                    ignored += glob.glob(
                        experimental_folder + line + "/**/*py", recursive=True
                    )
            for f in ignored:
                experimental_files.remove(f)
        for f in experimental_files:
            splits = f.split(os.sep)
            file_name = ".".join(splits[-splits[::-1].index("..") :])
            module_name = file_name[: file_name.find(".py")]
            importlib.import_module(module_name)

    registry.register("imports_setup", True)


def dict_set_recursively(dictionary, key_sequence, val):
    top_key = key_sequence.pop(0)
    if len(key_sequence) == 0:
        dictionary[top_key] = val
    else:
        if top_key not in dictionary:
            dictionary[top_key] = {}
        dict_set_recursively(dictionary[top_key], key_sequence, val)


def parse_value(value):
    """
    Parse string as Python literal if possible and fallback to string.
    """
    try:
        return ast.literal_eval(value)
    except (ValueError, SyntaxError):
        # Use as string if nothing else worked
        return value


def create_dict_from_args(args: list, sep: str = "."):
    """
    Create a (nested) dictionary from console arguments.
    Keys in different dictionary levels are separated by sep.
    """
    return_dict = {}
    for arg in args:
        arg = arg.strip("--")
        try:
            keys_concat, val = arg.split("=", 1)
            val = parse_value(val)
            key_sequence = keys_concat.split(sep)
            dict_set_recursively(return_dict, key_sequence, val)
        except:
            pass
    return return_dict


def load_config(path: str, previous_includes: list = []):
    path = Path(path)
    if path in previous_includes:
        raise ValueError(
            f"Cyclic config include detected. {path} included in sequence {previous_includes}."
        )
    previous_includes = previous_includes + [path]

    direct_config = yaml.safe_load(open(path, "r"))

    # Load config from included files.
    if "includes" in direct_config:
        includes = direct_config.pop("includes")
    else:
        includes = []
    if not isinstance(includes, list):
        raise AttributeError(
            "Includes must be a list, '{}' provided".format(type(includes))
        )

    config = {}
    duplicates_warning = []
    duplicates_error = []

    for include in includes:
        include_config, inc_dup_warning, inc_dup_error = load_config(
            include, previous_includes
        )
        duplicates_warning += inc_dup_warning
        duplicates_error += inc_dup_error

        # Duplicates between includes causes an error
        config, merge_dup_error = merge_dicts(config, include_config)
        duplicates_error += merge_dup_error

    # Duplicates between included and main file causes warnings
    config, merge_dup_warning = merge_dicts(config, direct_config)
    duplicates_warning += merge_dup_warning

    return config, duplicates_warning, duplicates_error


def build_config(args, args_override):
    config, duplicates_warning, duplicates_error = load_config(args.config_yml)
    if len(duplicates_warning) > 0:
        logging.warning(
            f"Overwritten config parameters from included configs "
            f"(non-included parameters take precedence): {duplicates_warning}"
        )
    if len(duplicates_error) > 0:
        raise ValueError(
            f"Conflicting (duplicate) parameters in simultaneously "
            f"included configs: {duplicates_error}"
        )

    # Check for overridden parameters.
    if args_override != []:
        overrides = create_dict_from_args(args_override)
        config, _ = merge_dicts(config, overrides)
    if args.molecule is not None:
        assert (
            config["name"] == "md17" or config["name"] == "md22"
        ), "only MD17 and MD22 datasets admit specification of the molecule."
        config["molecule"] = args.molecule
    if args.size is not None:
        config["size"] = args.size
        config["dataset"]["size"] = args.size

    # Some other flags.
    config["mode"] = args.mode
    config["timestamp_id"] = args.timestamp_id
    config["seed"] = args.seed
    config["is_debug"] = args.debug
    config["run_dir"] = args.run_dir
    config["print_every"] = args.print_every
    config["amp"] = args.amp
    config["checkpoint"] = args.checkpoint
    config["cpu"] = args.cpu
    # Submit
    config["submit"] = args.submit
    config["summit"] = args.summit
    # Distributed
    config["distributed"] = args.distributed
    config["local_rank"] = args.local_rank
    config["distributed_port"] = args.distributed_port
    config["world_size"] = args.num_nodes * args.num_gpus
    config["distributed_backend"] = args.distributed_backend
    config["noddp"] = args.no_ddp

    if args.identifier is not None:
        config["identifier"] = args.identifier
    elif "identifier" not in config:
        config["identifier"] = ""

    if args.cutoff is not None:
        config["model"]["cutoff"] = args.cutoff

    if args.patience is not None:
        config["optim"]["patience"] = args.patience

    if args.max_epochs:
        config["optim"]["max_epochs"] = args.max_epochs

    return config


def compose_data_cfg(data_cfg):
    dataset_name = data_cfg["name"]
    if dataset_name == "md17":
        data_cfg["src"] = os.path.join(data_cfg["src"], data_cfg["molecule"])
        data_cfg["name"] = "md17-" + data_cfg["molecule"]
    src = os.path.join(data_cfg["src"], data_cfg["size"])
    data_cfg["src"] = os.path.join(src, "train")

    norm_stats = np.load(os.path.join(src, "metadata.npy"), allow_pickle=True).item()
    if not data_cfg["normalize_labels"]:
        # always substract mean of energy, even when <normalize_labels==False>.
        # this is done in <trainer.load_datasets>.
        data_cfg["target_mean"] = float(norm_stats["e_mean"])
        data_cfg["target_std"] = 1.0
        data_cfg["grad_target_mean"] = 0.0
        data_cfg["grad_target_std"] = 1.0
        data_cfg["normalize_labels"] = True
    else:
        data_cfg["target_mean"] = float(norm_stats["e_mean"])
        data_cfg["target_std"] = float(norm_stats["e_std"])
        data_cfg["grad_target_mean"] = float(norm_stats["f_mean"])
        data_cfg["grad_target_std"] = float(norm_stats["f_std"])
    # train, val, test
    return data_cfg


def create_grid(base_config, sweep_file):
    def _flatten_sweeps(sweeps, root_key="", sep="."):
        flat_sweeps = []
        for key, value in sweeps.items():
            new_key = root_key + sep + key if root_key else key
            if isinstance(value, collections.MutableMapping):
                flat_sweeps.extend(_flatten_sweeps(value, new_key).items())
            else:
                flat_sweeps.append((new_key, value))
        return collections.OrderedDict(flat_sweeps)

    def _update_config(config, keys, override_vals, sep="."):
        for key, value in zip(keys, override_vals):
            key_path = key.split(sep)
            child_config = config
            for name in key_path[:-1]:
                child_config = child_config[name]
            child_config[key_path[-1]] = value
        return config

    sweeps = yaml.safe_load(open(sweep_file, "r"))
    flat_sweeps = _flatten_sweeps(sweeps)
    keys = list(flat_sweeps.keys())
    values = list(itertools.product(*flat_sweeps.values()))

    configs = []
    for i, override_vals in enumerate(values):
        config = copy.deepcopy(base_config)
        config = _update_config(config, keys, override_vals)
        config["identifier"] = config["identifier"] + f"_run{i}"
        configs.append(config)
    return configs


def save_experiment_log(args, jobs, configs):
    log_file = args.logdir / "exp" / time.strftime("%Y-%m-%d-%I-%M-%S%p.log")
    log_file.parent.mkdir(exist_ok=True, parents=True)
    with open(log_file, "w") as f:
        for job, config in zip(jobs, configs):
            print(
                json.dumps(
                    {
                        "config": config,
                        "slurm_id": job.job_id,
                        "timestamp": time.strftime("%I:%M:%S%p %Z %b %d, %Y"),
                    }
                ),
                file=f,
            )
    return log_file


def merge_dicts(dict1: dict, dict2: dict):
    """Recursively merge two dictionaries.
    Values in dict2 override values in dict1. If dict1 and dict2 contain a dictionary as a
    value, this will call itself recursively to merge these dictionaries.
    This does not modify the input dictionaries (creates an internal copy).
    Additionally returns a list of detected duplicates.
    Adapted from https://github.com/TUM-DAML/seml/blob/master/seml/utils.py

    Parameters
    ----------
    dict1: dict
        First dict.
    dict2: dict
        Second dict. Values in dict2 will override values from dict1 in case they share the same key.

    Returns
    -------
    return_dict: dict
        Merged dictionaries.
    """
    if not isinstance(dict1, dict):
        raise ValueError(f"Expecting dict1 to be dict, found {type(dict1)}.")
    if not isinstance(dict2, dict):
        raise ValueError(f"Expecting dict2 to be dict, found {type(dict2)}.")

    return_dict = copy.deepcopy(dict1)
    duplicates = []

    for k, v in dict2.items():
        if k not in dict1:
            return_dict[k] = v
        else:
            if isinstance(v, dict) and isinstance(dict1[k], dict):
                return_dict[k], duplicates_k = merge_dicts(dict1[k], dict2[k])
                duplicates += [f"{k}.{dup}" for dup in duplicates_k]
            else:
                return_dict[k] = dict2[k]
                duplicates.append(k)

    return return_dict, duplicates


class SeverityLevelBetween(logging.Filter):
    def __init__(self, min_level, max_level):
        super().__init__()
        self.min_level = min_level
        self.max_level = max_level

    def filter(self, record):
        return self.min_level <= record.levelno < self.max_level


def setup_logging():
    root = logging.getLogger()

    # Perform setup only if logging has not been configured
    if not root.hasHandlers():
        root.setLevel(logging.INFO)

        log_formatter = logging.Formatter(
            "%(asctime)s (%(levelname)s): %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
        )

        # Send INFO to stdout
        handler_out = logging.StreamHandler(sys.stdout)
        handler_out.addFilter(SeverityLevelBetween(logging.INFO, logging.WARNING))
        handler_out.setFormatter(log_formatter)
        root.addHandler(handler_out)

        # Send WARNING (and higher) to stderr
        handler_err = logging.StreamHandler(sys.stderr)
        handler_err.setLevel(logging.WARNING)
        handler_err.setFormatter(log_formatter)
        root.addHandler(handler_err)


def compute_neighbors(data, edge_index):
    # Get number of neighbors
    # segment_coo assumes sorted index
    ones = edge_index[1].new_ones(1).expand_as(edge_index[1])
    num_neighbors = segment_coo(ones, edge_index[1], dim_size=data.natoms.sum())

    # Get number of neighbors per image
    image_indptr = torch.zeros(
        data.natoms.shape[0] + 1, device=data.pos.device, dtype=torch.long
    )
    image_indptr[1:] = torch.cumsum(data.natoms, dim=0)
    neighbors = segment_csr(num_neighbors, image_indptr)
    return neighbors


def lattice_params_to_matrix_torch(lengths, angles):
    """Batched torch version to compute lattice matrix from params.
    lengths: torch.Tensor of shape (N, 3), unit A
    angles: torch.Tensor of shape (N, 3), unit degree
    """
    angles_r = torch.deg2rad(angles)
    coses = torch.cos(angles_r)
    sins = torch.sin(angles_r)

    val = (coses[:, 0] * coses[:, 1] - coses[:, 2]) / (sins[:, 0] * sins[:, 1])
    # Sometimes rounding errors result in values slightly > 1.
    val = torch.clamp(val, -1.0, 1.0)
    gamma_star = torch.arccos(val)

    vector_a = torch.stack(
        [
            lengths[:, 0] * sins[:, 1],
            torch.zeros(lengths.size(0), device=lengths.device),
            lengths[:, 0] * coses[:, 1],
        ],
        dim=1,
    )
    vector_b = torch.stack(
        [
            -lengths[:, 1] * sins[:, 0] * torch.cos(gamma_star),
            lengths[:, 1] * sins[:, 0] * torch.sin(gamma_star),
            lengths[:, 1] * coses[:, 0],
        ],
        dim=1,
    )
    vector_c = torch.stack(
        [
            torch.zeros(lengths.size(0), device=lengths.device),
            torch.zeros(lengths.size(0), device=lengths.device),
            lengths[:, 2],
        ],
        dim=1,
    )

    return torch.stack([vector_a, vector_b, vector_c], dim=1)


def radius_graph(positions, n_node, radius, bonds=None, add_self_edges=True):
    batch = torch.arange(len(n_node)).to(n_node.device).repeat_interleave(n_node, dim=0)
    senders, receivers = pyg_radius_graph(positions, radius, batch, loop=add_self_edges)
    if bonds is not None:
        edge_indices = torch.cat([senders.unsqueeze(1), receivers.unsqueeze(1)], dim=1)
        all_edges = torch.cat([edge_indices, bonds], dim=0)
        all_edges, counts = torch.unique(all_edges, dim=0, return_counts=True)
        edge_types = (counts > 1).int()
        senders, receivers = all_edges[:, 0], all_edges[:, 1]
    else:
        edge_types = None
    # displacements normalized with radius.
    displacements = (positions[senders] - positions[receivers]) / radius
    distances = displacements.norm(dim=-1, keepdim=True)
    return senders, receivers, displacements, distances, edge_types


def radius_graph_pbc(data, radius, max_num_neighbors_threshold, topk_per_pair=None):
    """Computes pbc graph edges under pbc.
    topk_per_pair: (num_atom_pairs,), select topk edges per atom pair
    Note: topk should take into account self-self edge for (i, i)
    """
    atom_pos = data.pos
    num_atoms = data.natoms
    lattice = data.cell
    batch_size = len(num_atoms)
    device = atom_pos.device
    # import pdb; pdb.set_trace()
    # Before computing the pairwise distances between atoms, first create a list of atom indices to compare for the entire batch
    num_atoms_per_image = num_atoms
    num_atoms_per_image_sqr = (num_atoms_per_image**2).long()

    # index offset between images
    index_offset = torch.cumsum(num_atoms_per_image, dim=0) - num_atoms_per_image

    index_offset_expand = torch.repeat_interleave(index_offset, num_atoms_per_image_sqr)
    num_atoms_per_image_expand = torch.repeat_interleave(
        num_atoms_per_image, num_atoms_per_image_sqr
    )

    # Compute a tensor containing sequences of numbers that range from 0 to num_atoms_per_image_sqr for each image
    # that is used to compute indices for the pairs of atoms. This is a very convoluted way to implement
    # the following (but 10x faster since it removes the for loop)
    # for batch_idx in range(batch_size):
    #    batch_count = torch.cat([batch_count, torch.arange(num_atoms_per_image_sqr[batch_idx], device=device)], dim=0)
    num_atom_pairs = torch.sum(num_atoms_per_image_sqr)
    index_sqr_offset = (
        torch.cumsum(num_atoms_per_image_sqr, dim=0) - num_atoms_per_image_sqr
    )
    index_sqr_offset = torch.repeat_interleave(
        index_sqr_offset, num_atoms_per_image_sqr
    )
    atom_count_sqr = torch.arange(num_atom_pairs, device=device) - index_sqr_offset

    # Compute the indices for the pairs of atoms (using division and mod)
    # If the systems get too large this apporach could run into numerical precision issues
    index1 = (
        (atom_count_sqr // num_atoms_per_image_expand)
    ).long() + index_offset_expand
    index2 = (atom_count_sqr % num_atoms_per_image_expand).long() + index_offset_expand
    # Get the positions for each atom
    pos1 = torch.index_select(atom_pos, 0, index1.long())
    pos2 = torch.index_select(atom_pos, 0, index2.long())

    unit_cell = torch.tensor(OFFSET_LIST, device=device).float()
    num_cells = len(unit_cell)
    unit_cell_per_atom = unit_cell.view(1, num_cells, 3).repeat(len(index2), 1, 1)
    unit_cell = torch.transpose(unit_cell, 0, 1)
    unit_cell_batch = unit_cell.view(1, 3, num_cells).expand(batch_size, -1, -1)

    # Compute the x, y, z positional offsets for each cell in each image
    data_cell = torch.transpose(lattice, 1, 2)
    pbc_offsets = torch.bmm(data_cell, unit_cell_batch)

    pbc_offsets_per_atom = torch.repeat_interleave(
        pbc_offsets, num_atoms_per_image_sqr, dim=0
    )

    # Expand the positions and indices for the 9 cells
    pos1 = pos1.view(-1, 3, 1).expand(-1, -1, num_cells)
    pos2 = pos2.view(-1, 3, 1).expand(-1, -1, num_cells)
    index1 = index1.view(-1, 1).repeat(1, num_cells).view(-1)
    index2 = index2.view(-1, 1).repeat(1, num_cells).view(-1)
    # Add the PBC offsets for the second atom
    pos2 = pos2 + pbc_offsets_per_atom

    # Compute the squared distance between atoms
    atom_distance_sqr = torch.sum((pos1 - pos2) ** 2, dim=1)

    if topk_per_pair is not None:
        assert topk_per_pair.size(0) == num_atom_pairs
        atom_distance_sqr_sort_index = torch.argsort(atom_distance_sqr, dim=1)
        assert atom_distance_sqr_sort_index.size() == (num_atom_pairs, num_cells)
        atom_distance_sqr_sort_index = (
            atom_distance_sqr_sort_index
            + torch.arange(num_atom_pairs, device=device)[:, None] * num_cells
        ).view(-1)
        topk_mask = (
            torch.arange(num_cells, device=device)[None, :] < topk_per_pair[:, None]
        )
        topk_mask = topk_mask.view(-1)
        topk_indices = atom_distance_sqr_sort_index.masked_select(topk_mask)

        topk_mask = torch.zeros(num_atom_pairs * num_cells, device=device)
        topk_mask.scatter_(0, topk_indices, 1.0)
        topk_mask = topk_mask.bool()

    atom_distance_sqr = atom_distance_sqr.view(-1)

    # Remove pairs that are too far apart
    mask_within_radius = torch.le(atom_distance_sqr, radius * radius)
    # Remove pairs with the same atoms (distance = 0.0)
    mask_not_same = torch.gt(atom_distance_sqr, 0.0001)
    mask = torch.logical_and(mask_within_radius, mask_not_same)
    index1 = torch.masked_select(index1, mask)
    index2 = torch.masked_select(index2, mask)
    unit_cell = torch.masked_select(
        unit_cell_per_atom.view(-1, 3), mask.view(-1, 1).expand(-1, 3)
    )
    unit_cell = unit_cell.view(-1, 3)
    if topk_per_pair is not None:
        topk_mask = torch.masked_select(topk_mask, mask)

    num_neighbors = torch.zeros(len(atom_pos), device=device)
    num_neighbors.index_add_(0, index1.long(), torch.ones(len(index1), device=device))
    num_neighbors = num_neighbors.long()
    max_num_neighbors = torch.max(num_neighbors).long()

    # Compute neighbors per image
    _max_neighbors = copy.deepcopy(num_neighbors)
    _max_neighbors[_max_neighbors > max_num_neighbors_threshold] = (
        max_num_neighbors_threshold
    )
    _num_neighbors = torch.zeros(len(atom_pos) + 1, device=device).long()
    _natoms = torch.zeros(num_atoms.shape[0] + 1, device=device).long()
    _num_neighbors[1:] = torch.cumsum(_max_neighbors, dim=0)
    _natoms[1:] = torch.cumsum(num_atoms, dim=0)
    num_neighbors_image = _num_neighbors[_natoms[1:]] - _num_neighbors[_natoms[:-1]]

    atom_distance_sqr = torch.masked_select(atom_distance_sqr, mask)
    # return torch.stack((index2, index1)), unit_cell, atom_distance_sqr.sqrt(), num_neighbors_image

    # If max_num_neighbors is below the threshold, return early
    if (
        max_num_neighbors <= max_num_neighbors_threshold
        or max_num_neighbors_threshold <= 0
    ):
        return (
            torch.stack((index2, index1)),
            unit_cell,
            atom_distance_sqr.sqrt(),
            num_neighbors_image,
        )
    # atom_distance_sqr.sqrt() distance

    # Create a tensor of size [num_atoms, max_num_neighbors] to sort the distances of the neighbors.
    # Fill with values greater than radius*radius so we can easily remove unused distances later.
    distance_sort = torch.zeros(len(atom_pos) * max_num_neighbors, device=device).fill_(
        radius * radius + 1.0
    )

    # Create an index map to map distances from atom_distance_sqr to distance_sort
    index_neighbor_offset = torch.cumsum(num_neighbors, dim=0) - num_neighbors
    index_neighbor_offset_expand = torch.repeat_interleave(
        index_neighbor_offset, num_neighbors
    )
    index_sort_map = (
        index1 * max_num_neighbors
        + torch.arange(len(index1), device=device)
        - index_neighbor_offset_expand
    ).long()
    distance_sort.index_copy_(0, index_sort_map, atom_distance_sqr)
    distance_sort = distance_sort.view(len(atom_pos), max_num_neighbors)

    # Sort neighboring atoms based on distance
    distance_sort, index_sort = torch.sort(distance_sort, dim=1)
    # Select the max_num_neighbors_threshold neighbors that are closest
    distance_sort = distance_sort[:, :max_num_neighbors_threshold]
    index_sort = index_sort[:, :max_num_neighbors_threshold]

    # Offset index_sort so that it indexes into index1
    index_sort = index_sort + index_neighbor_offset.view(-1, 1).expand(
        -1, max_num_neighbors_threshold
    )
    # Remove "unused pairs" with distances greater than the radius
    mask_within_radius = torch.le(distance_sort, radius * radius)
    index_sort = torch.masked_select(index_sort, mask_within_radius)

    # At this point index_sort contains the index into index1 of the closest max_num_neighbors_threshold neighbors per atom
    # Create a mask to remove all pairs not in index_sort
    mask_num_neighbors = torch.zeros(len(index1), device=device).bool()
    mask_num_neighbors.index_fill_(0, index_sort, True)

    # Finally mask out the atoms to ensure each atom has at most max_num_neighbors_threshold neighbors
    index1 = torch.masked_select(index1, mask_num_neighbors)
    index2 = torch.masked_select(index2, mask_num_neighbors)
    unit_cell = torch.masked_select(
        unit_cell.view(-1, 3), mask_num_neighbors.view(-1, 1).expand(-1, 3)
    )
    unit_cell = unit_cell.view(-1, 3)

    if topk_per_pair is not None:
        topk_mask = torch.masked_select(topk_mask, mask_num_neighbors)

    edge_index = torch.stack((index2, index1))
    atom_distance_sqr = torch.masked_select(atom_distance_sqr, mask_num_neighbors)

    return edge_index, unit_cell, atom_distance_sqr.sqrt(), num_neighbors_image
    # atom_distance_sqr.sqrt() distance


def get_pbc_distances(
    pos,
    edge_index,
    lattice,
    cell_offsets,
    num_atoms,
    return_offsets=False,
    return_distance_vec=False,
):
    j_index, i_index = edge_index
    num_edges = get_n_edge(j_index, num_atoms)
    distance_vectors = pos[j_index.long()] - pos[i_index.long()]

    # correct for pbc
    lattice_edges = torch.repeat_interleave(lattice, num_edges, dim=0)
    offsets = torch.einsum("bi,bij->bj", cell_offsets, lattice_edges)
    distance_vectors += offsets

    # compute distances
    distances = distance_vectors.norm(dim=-1)

    out = {
        "edge_index": edge_index,
        "distances": distances,
    }

    if return_distance_vec:
        out["distance_vec"] = distance_vectors

    if return_offsets:
        out["offsets"] = offsets

    return out


def get_n_edge(senders, n_node):
    """
    return number of edges for each graph in the batched graph.
    Has the same shape as <n_node>.
    """
    index_offsets = torch.cat(
        [torch.zeros(1).to(n_node.device), torch.cumsum(n_node, -1)], dim=-1
    )
    n_edge = torch.LongTensor(
        [
            torch.logical_and(
                senders >= index_offsets[i], senders < index_offsets[i + 1]
            ).sum()
            for i in range(len(n_node))
        ]
    ).to(n_node.device)
    return n_edge
